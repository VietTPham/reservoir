/* HJSON configuration file for use with MacLean Lab SNN experiments
 *
 * The HJSON syntax is fully defined here: https://hjson.github.io/
 * ---------------------------------------------------------------------------
 * This file is configured for a model trained to match a lightly-noised
 * sinusoid pattern. Its primary purpose is to serve as an example and/or
 * template for how the repository structure works.
 *
 * Some small notes about encoding Python variables in HJSON:
 * - HJSON booleans are lowercase (`true` & `false`, not `True` & `False`)
 * - Use `null` in HJSON where you want `None` in Python
 */
{
    #┬───────────────────────────────────────────────────────────────────────╮
    #┤ File Saving                                                           │
    #┼ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ┤
    #┤ Configure what gets saved, where, and how. Please be mindful of other │
    #┤ researchers and their data when adjusting these settings.             │
    #┤                                                                       │
    #┤ Filepaths are relative to where the script was invoked (not           │
    #┤ necessarily) where the script is located. See the documentation below │
    #┤ for how directories relate to each other and what each should         │
    #┤ contain.                                                              │
    #┼ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ┤
    #┤******************* THESE SETTINGS CAN DELETE FILES *******************│
    #┴───────────────────────────────────────────────────────────────────────╯
    save:
    {
        #┬───────────────────────────────────────────────────────────────────╮
        #┤ Directories                                                       │
        #┴───────────────────────────────────────────────────────────────────╯

        // Directory containing this experiment's output. Prefixes all other
        // directory paths.
        //
        // Full path: {exp_dir}
        //
        // Manditory variable.
        exp_dir: /data/experiments/fwd-pipeline-inputspikeregen-newl23-owerlr-runlonger-SGD

        // Collection of directories which will be placed inside exp_dir
        //
        // Manditory namespace.
        subdirs:
        {
            #┬───────────────────────────────────────────────────────────────╮
            #┤ TensorFlow Directories                                        │
            #┴───────────────────────────────────────────────────────────────╯

            // Directory storing checkpoints intended to restore models for
            // training (`.ckpt` or `.h5` files, generally) or holding weights
            //
            // Full path: {exp_dir}\{checkpoint_dir}
            checkpoint_dir: checkpoints

            #┬───────────────────────────────────────────────────────────────╮
            #┤ TensorBoard Directories                                       │
            #┴───────────────────────────────────────────────────────────────╯

            // Directory storing summary data from one or more training
            // sessions
            summary_dir: tensorboard/summaries

            // Directory storing logdirs (*only* for use with TensorBoard)
            profile_dir: tensorboard/profile

            #┬───────────────────────────────────────────────────────────────╮
            #┤ Other Directories                                             │
            #┴───────────────────────────────────────────────────────────────╯

            // Used to store plots
            plot_dir: plots

            // Big everything jumbo place of stuff (the important stuff)
            main_output_dir: npz-data
        }

        #┬───────────────────────────────────────────────────────────────────╮
        #┤ Flags (Mandatory)                                                 │
        #┴───────────────────────────────────────────────────────────────────╯

        // When enabled, the exp_dir will have a number suffixed to avoid
        // overwriting saved data
        avoid_overwrite: false

        // If avoid_overwrite is set to false, and exp_dir overwrites a
        // directory, this will purge the contents of the old directory. This
        // is to avoid mixing data from different experiments, but be careful.
        hard_overwrite: true

        // Experiment directories will be suffixed by a UNIX timestamp
        timestamp: false

        // Save a copy of this file to exp_dir, so there's a record of what
        // parameters the experiment was run with (won't save any indication
        // of what the `.py` files were like)
        log_config: true

        // Enable/disable any additional processing on the data performed
        // after training (doesn't do anything right now [?])
        postprocess: true

        #┬───────────────────────────────────────────────────────────────────╮
        #┤ Flags (Supplemental)                                              │
        #┴───────────────────────────────────────────────────────────────────╯

        /* if there are any flags for saving particular to your experiment,
         * include them here */
        save_npz: true
        save_loss_only: false
    }

    #┬───────────────────────────────────────────────────────────────────────╮
    #┤ Model-Specific Parameters                                             │
    #┼ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ┤
    #┤ Any parameter used to define your experiment's models and layers.     │
    #┴───────────────────────────────────────────────────────────────────────╯
    model:
    {
        type: std_backprop

        cell:
        {
            type: ExInALIF

            freewiring: false   // now the term for our original unprincipled use of "rewiring"

            rewiring: true   // now the term for permitting a new connection to grow if/when an existing connection disappears

            units: 300   // number of units in the layer

            thr: -50.4   // threshold [mV]
            EL: -70.6    // [mV]
            n_refrac: 4  // number of refractory ms
            tau: 20.0    //

            dampening_factor: 0.3  // for LIF variants
            // dampening_factor: 0.2  // for AdEx variants

            frac_e: 0.8

            specify_input: false

            // These parameters are used for input-to-main layer if specify_input is true
            p_input: 0.55 // this is the one we have been using, which is to excitatory units only
            // we would use the following if we have input to both e and i units
            p_to_e: 0.2
            p_to_i: 0.1

            // Multiplier for input weights (to increase or decrease strengths generated from IMG)
            input_multiplier: 15

            // These parameters will only be used for ExIn neurons
            p_ee: 0.160
            //p_ei: 0.244
            p_ei: 0.205
            //p_ie: 0.318
            p_ie: 0.252
            //p_ii: 0.343
            p_ii: 0.284

            // ...

            beta: 0.16
            tau_adaptation: 100

            // μ for normal distribution (exponentiated for lognormal weights)
            mu: -0.64

            // σ for normal distribution (exponentiated for lognormal weights)
            sigma: 0.51

            // A bunch of AdEx parameters all at once with no context
            tauw: 144
            a: 0.000004
            b: 0.0000805
            gL: 0.00003
            C: 281
            deltaT: 2
            V_reset: -51
        }
    }

    #┬───────────────────────────────────────────────────────────────────────╮
    #┤ Data Config                                                           │
    #┼ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ┤
    #┤ Variables parameterizing the datasets used to train the model.        │
    #┴───────────────────────────────────────────────────────────────────────╯
    data:
    {
        type: ccd

        // file containing firing rate data for CCD (to regenerate spikes)
        rate_npy:
        /data/datasets/CNN_outputs/ch8_abs_ccd_rates.npy

        // file containing coherence change data (CCD) corresponding to the rates
        coh_npz:
        /data/datasets/CNN_outputs/ch8_abs_ccd_coherences.npz

        // file containing spike data for CCD or DMC
        //spike_npz:
        ///home/macleanlab/stim/dmc/2021-08-05-1225/CNN_outputs/spike_train.npz
        spike_npz:
        /data/datasets/CNN_outputs/spike_train_mixed_limlifetime_abs.npz

        // file containing sample match/non-match data
        match_npy:
        /home/macleanlab/stim/dmc/2021-08-05-1225/CNN_outputs/cat_time_series.npy

        //
        seq_len: 4080

        // number of input units
        n_input: 16
    }

    #┬───────────────────────────────────────────────────────────────────────╮
    #┤ Logging Config                                                        │
    #┼ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ┤
    #┤ Choose what to log during training and how.                           │
    #┴───────────────────────────────────────────────────────────────────────╯
    log:
    {
        // logger to use
        type: std_timeseries

        // Whitelist and blacklist for logvars
        //
        // Logvars with labels in these lists won't be collected or processed
        // at all by the logger. A value of `null` will disable the list, a
        // value of [] will create an empty but functioning white/black -list.
        //
        // Blacklist values take precedence over whitelist values.
        //
        // TODO: add list of potential logged variables
        logvar_whitelist: null
        logvar_blacklist: null

        // Whitelist and blacklist for writing to disk
        //
        // Unlike the logvar lists, these values will still be stored in the
        // logger, they just won't be written to disk. This is useful if you
        // want to generate plots but not keep the underlying data.
        todisk_whitelist: [
            step_loss
            epoch_loss
            tv0.postweights
            tv1.postweights
            tv2.postweights
            tv0.gradients
            tv1.gradients
            tv2.gradients
        ]
        todisk_blacklist: null

        // Save npz files or not
        log_npz: true

        // Save logging values to disk every n epochs
        post_every: 10

        // Toggle the TensorBoard profiler
        run_profiler: false

        // If enabled, the profiler will run on each epoch in the list below
        profiler_epochs: [
            4
        ]

        // Filter for a subset of the logging procedures in the training loop
        layer_whitelist: [
            rnn
        ]

        // Floating point precision of numpy arrays saved to disk (fewer bits
        // consume less memory on disk)
        //
        // 64  -->  ~16 decimal precision
        // 32  -->  ~7 decimal precision
        // 16  -->  ~3 decimal precision
        float_dtype: float16

        // Integer size
        int_dtype: uint16

        #┬───────────────────────────────────────────────────────────────────╮
        #┤ Model Saving and Checkpoints                                      │
        #┴───────────────────────────────────────────────────────────────────╯

        // [!] still trying to figure out how to save models as SavedModel
        // [!] we can save checkpoints and read them with
        //     tf.train.load_checkpointbut I'm still trying to figure out how
        //     to integrate them into the training infrastructure

        // Create a checkpoint every N epochs (checkpoints disabled if N=0)
        ckpt_freq: 0

        // Maximum number of checkpoints saved per experiment (will save the
        // most recent)
        ckpt_lim: 0
    }

    #┬───────────────────────────────────────────────────────────────────────╮
    #┤ Training Config                                                       │
    #┼ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ┤
    #┤ Variables parameterizing training.                                    │
    #┴───────────────────────────────────────────────────────────────────────╯
    train:
    {
        type: std_single_task

        input_trainable: true
        //note that when false, this means tv0 is the recurrent weights instead of tv1

        output_trainable: true
        //note that when false, this means there is no tv associated with the output layer

        learning_rate: 0.001

        output_learning_rate: 0.00001

        // number of trials in batch
        batch_size: 10

        // number of batches in an epoch
        n_batch: 10

        // number of epochs the model is fit over
        n_epochs: 1000

        target_rate: 0.02

        rate_cost: 10

        target_synch: 2.0

        synch_cost: 0.01

        target_conn: 0.266
        // mean of initial p's, which is imprecise

        conn_cost: 0.1
    }

    #┬───────────────────────────────────────────────────────────────────────╮
    #┤ Miscellaneous                                                         │
    #┼ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ┤
    #┤ Any other values useful to manipulate from this file.                 │
    #┴───────────────────────────────────────────────────────────────────────╯
    misc:
    {
        // time step
        dt: 1
    }
}
